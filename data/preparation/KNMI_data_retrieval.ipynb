{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be24c264",
   "metadata": {},
   "source": [
    "# Retrieving data from the KNMI API\n",
    "\n",
    "## Requests to the web-server\n",
    "\n",
    "KNMI is The Royal Netherlands Meteorological Institute (KNMI), which provides data on the meteorological indicators of different time granularity. According to the purposes of our project, we request the data from the platform's web servers as [suggested by the developers](https://www.knmi.nl/kennis-en-datacentrum/achtergrond/data-ophalen-vanuit-een-script) (the initial Bash code provided by them was 'translated' to Python).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d895f3",
   "metadata": {},
   "source": [
    "As we are requesting data for all stations and for a distinct set of variables, we specify them inside the code. The codebook could be observed on the KNMI [user-friendly data requesting interface](https://www.daggegevens.knmi.nl/klimatologie/uurgegevens). For our timeframe from the 1st Jan 2017 to the 1st Jan 2025, server is only capable to return data for one station at once and 'breaks' otherwise, so we are trying to follow one of the main best practices in data acquisition - use sleep() function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383df320",
   "metadata": {},
   "source": [
    "``` python\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy.stats import circmean\n",
    "\n",
    "# Define parameters\n",
    "base_url = \"https://www.daggegevens.knmi.nl/klimatologie/uurgegevens\"\n",
    "stations = [209, 210, 215, 225, 235, 240, 242, 248, 249, 251, 257, 258, 260, 265, 267, 269, 270, 273, 275, 277,\n",
    "            278, 279, 280, 283, 285, 286, 290, 308, 310, 311, 312, 313, 315, 316, 319, 323, 324, 330, 331, 340, 343,\n",
    "            344, 348, 350, 356, 370, 375, 377, 380, 391]\n",
    "\n",
    "start_date = \"20170101\"\n",
    "end_date = \"20250101\"\n",
    "variables = \"DD:FH:FF:P:U\"\n",
    "\n",
    "# Looping through stations to get respective data\n",
    "\n",
    "data_frames = []\n",
    "\n",
    "for station in stations:\n",
    "    print(f\"Retrieving data for station {station}...\")\n",
    "    post_data = {\n",
    "        \"start\": start_date,\n",
    "        \"end\": end_date,\n",
    "        \"vars\": variables,\n",
    "        \"stns\": station,\n",
    "        \"fmt\": \"csv\"\n",
    "    }\n",
    "    \n",
    "    response = requests.post(base_url, data=post_data)\n",
    "    time.sleep(1)  # Give server time to respond\n",
    "    \n",
    "    response_text = response.text\n",
    "    \n",
    "    # Remove comment lines\n",
    "    data_lines = [line for line in response_text.split(\"\\n\") if not line.startswith(\"#\") and line.strip()]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    if data_lines:\n",
    "        df = pd.read_csv(\n",
    "            io.StringIO(\"\\n\".join(data_lines)), \n",
    "            names=[\"STN\", \"YYYYMMDD\", \"HH\", \"DD\", \"FH\", \"FF\", \"P\", \"U\"],\n",
    "            dtype={\"STN\": int, \"YYYYMMDD\": int, \"HH\": int, \"DD\": str, \"FH\": str, \"FF\": str, \"P\": str, \"U\": str},\n",
    "            low_memory=False\n",
    "        )\n",
    "        data_frames.append(df)\n",
    "    time.sleep(3)  # Rest before next request\n",
    "\n",
    "# Concatenate all stations data into one final DataFrame\n",
    "final_df = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# Display sample data\n",
    "print(final_df.head())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6831833e",
   "metadata": {},
   "source": [
    "In the end, we get dataframe that contains:\n",
    "\n",
    "- STN, station number\n",
    "\n",
    "- YYYYMMDD, timestamp with year, month and day\n",
    "\n",
    "- HH, timestamp with hour (from 1 to 24)\n",
    "\n",
    "- DD, wind direction (in degrees) averaged over the last 10 minutes of the past hour (360 = north, 90 = east, 180 = south, 270 = west, 0 = windless 990 = variable.\n",
    "\n",
    "- FH, hourly average wind speed (in 0.1 m / s)\n",
    "    \n",
    "- FF, wind speed (in 0.1 m / s) averaged over the last 10 minutes of the last hour\n",
    "    \n",
    "- P, air pressure (in 0.1 hPa) traced to sea level, during observation\n",
    "    \n",
    "- U, relative humidity (in percentages) at an altitude of 1.50 m during observation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cabef87",
   "metadata": {},
   "source": [
    "## Data preprocessing and space optimization\n",
    "\n",
    "To reduce the amount of space taken by the dataset containing 3.2+ mln rows, we adjusted the datatypes for most of the columns.\n",
    "Besides that, before calculating the averages for the offshore and onshore stations, we decided to sacrifice 22K rows having \"990\" values for wind direction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57813540",
   "metadata": {},
   "source": [
    "``` python\n",
    "# Clean data from tabulation and spaces\n",
    "final_df['P'] = final_df['P'].str.replace(r'[\\s\\t]', '', regex=True)\n",
    "final_df['U'] = final_df['U'].str.replace(r'[\\s\\t]', '', regex=True)\n",
    "\n",
    "# Handle nulls with float types and optimize datatypes\n",
    "final_df['P'] = final_df['P'].replace(r'^\\s*$', float('nan'), regex=True).astype('float32')\n",
    "final_df['U'] = final_df['U'].replace(r'^\\s*$', float('nan'), regex=True).astype('float32')\n",
    "final_df['DD'] = final_df['DD'].replace(r'^\\s*$', float('nan'), regex=True).astype('float32')\n",
    "final_df['FH'] = final_df['FH'].replace(r'^\\s*$', float('nan'), regex=True).astype('float32')\n",
    "final_df['FF'] = final_df['FF'].replace(r'^\\s*$', float('nan'), regex=True).astype('float32')\n",
    "final_df['HH'] = final_df['HH'].astype('int8')\n",
    "final_df['STN'] = final_df['STN'].astype('int16')\n",
    "\n",
    "# Short info on datatypes and null values\n",
    "final_df.info()\n",
    "\n",
    "final_df['U'].isnull().sum()\n",
    "final_df['P'].isnull().sum()\n",
    "\n",
    "# Some of the stations have wind direction equal to \"990\", which means it was too unstable during the hour to calculate the average. We delete these rows to not harm the further calculations\n",
    "print(final_df[final_df[\"DD\"] == 990].shape[0])\n",
    "final_df = final_df[final_df[\"DD\"] != 990]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a431c03b",
   "metadata": {},
   "source": [
    "## Off- and onshore aggregation\n",
    "\n",
    "To conduct a further analysis for offshore and onshore wind energy production separately, we manually categorized the meteorological stations.\n",
    "\n",
    "Here is a list of the offshore stations:\n",
    "\n",
    "- Houtribdijk \n",
    "\n",
    "- Lauwersoog \n",
    "\n",
    "- Huibertgat\n",
    "\n",
    "- Hoorn Terschelling\n",
    "\n",
    "- Vlieland\n",
    "\n",
    "- De Kooy\n",
    "\n",
    "- IJmond\n",
    "\n",
    "- Wijk aan zee\n",
    "\n",
    "- IJmuiden\n",
    "\n",
    "- Valkenburg Zh\n",
    "\n",
    "- Wijdenes\n",
    "\n",
    "- Hoek van Holland\n",
    "\n",
    "- Oosterschelde\n",
    "\n",
    "- Schaar\n",
    "\n",
    "- Cadzand\n",
    "\n",
    "- Vlakte van De Raan\n",
    "\n",
    "- Stavoren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191ede8c",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "# List of offshore stations' numbers\n",
    "offshore_stations = { \n",
    "    209, 210, 225, 235, 242, 248, 251, 257, 258, 267, 277, 285, 308, 312, 313, 316, 330\n",
    "}\n",
    "\n",
    "final_df[\"is_offshore\"] = final_df[\"STN\"].isin(offshore_stations)\n",
    "\n",
    "# Saving full data\n",
    "#final_df.to_csv('all_data_2017_2025.csv', index = False)\n",
    "\n",
    "# Group and average while considering angular cyclicity\n",
    "def aggregate_weather(df):\n",
    "    aggregated_df = df.groupby(['YYYYMMDD', 'HH']).agg({\n",
    "        'DD': lambda x: circmean(x.dropna(), high=360, low=0) if not x.dropna().empty else np.nan,\n",
    "        'FH': 'mean',\n",
    "        'FF': 'mean',\n",
    "        'P': 'mean',\n",
    "        'U': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Add full_datetime column directly with proper formatting\n",
    "    aggregated_df['full_datetime'] = pd.to_datetime(aggregated_df['YYYYMMDD'].astype(str), format='%Y%m%d').dt.strftime('%Y-%m-%d') + '-' + aggregated_df['HH'].astype(str).str.zfill(2)\n",
    "    \n",
    "    return aggregated_df\n",
    "\n",
    "# Compute averages for onshore and offshore\n",
    "avg_onshore_meteo_df = aggregate_weather(final_df[final_df['is_offshore'] == False])\n",
    "\n",
    "avg_offshore_meteo_df = aggregate_weather(final_df[final_df['is_offshore'] == True])\n",
    "\n",
    "avg_onshore_meteo_df.info()\n",
    "avg_offshore_meteo_df.info()\n",
    "\n",
    "# Renaming the variables\n",
    "column_names = ['year_mon_day', 'hour', 'wind_dir_avg_10', 'wind_speed_h_avg', 'wind_speed_avg_10', 'air_pressure', 'humidity', 'full_datetime']\n",
    "\n",
    "avg_onshore_meteo_df.columns = column_names\n",
    "avg_offshore_meteo_df.columns = column_names\n",
    "\n",
    "\n",
    "# Saving data\n",
    "#avg_onshore_meteo_df.to_csv('avg_onshore_meteo_2017_2025.csv', index = False)\n",
    "\n",
    "#avg_offshore_meteo_df.to_csv('avg_offshore_meteo_2017_2025.csv', index = False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7915b521",
   "metadata": {},
   "source": [
    "## Merging datasets\n",
    "\n",
    "After both energy production and meteorological indicators data were obtained, dataframes were merged to the final csv files for the further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c474eb9",
   "metadata": {},
   "source": [
    "``` python\n",
    "# Load energy production data\n",
    "energy_onshore_df = pd.read_csv(\"data/preparation/WindOnShore_data_2017_2025_clean.csv\", index_col=0)\n",
    "energy_offshore_df = pd.read_csv(\"data/preparation/WindOffShore_data_2017_2025_clean.csv\", index_col=0)\n",
    "\n",
    "# Explore variables in energy data\n",
    "energy_onshore_df.info()\n",
    "\n",
    "# Merge data\n",
    "onshore_merged = pd.merge(avg_onshore_meteo_df, energy_onshore_df, left_on='full_datetime',right_on='correct_days')\n",
    "offshore_merged = pd.merge(avg_offshore_meteo_df, energy_offshore_df, left_on='full_datetime',right_on='correct_days')\n",
    "\n",
    "# Save data\n",
    "onshore_merged.to_csv('data/final_onshore_data_2017_2025.csv', index = False)\n",
    "offshore_merged.to_csv('data/final_offshore_data_2017_2025.csv', index = False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015be460",
   "metadata": {},
   "source": [
    "Final datasets contain 70151 rows each, representing hourly data from 1am 2017-01-01 until 11pm 2025-01-01.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
